model:
  target: evomerge.CausalLM
  params:
    model_path: nlp-waseda/llm-jp-invoice-13b
    template: ja-instruct
    model_kwargs:
      torch_dtype: torch.float16
      device_map: "auto"  # For large model efficient loading
    generation_config:
      max_new_tokens: 768
      do_sample: false
      temperature: 0.1
      top_p: 0.95
      repetition_penalty: 1.2
      num_beams: 3
eval:
    - target: evomerge.eval.JaTextExtraction
      params:
        loader_kwargs:
          batch_size: 4  # Reduced batch size for larger model
          num_workers: 2
    - target: evomerge.eval.JaFieldExtraction
      params:
        loader_kwargs:
          batch_size: 4  # Reduced batch size for larger model
          num_workers: 2